import numpy as np
import pandas as pd
import math
import tensorflow as tf   # See project README
import itertools
from PINN_solve import PINN_solve
import matplotlib.pyplot as plt



def PINN_convergence_plots(df):
    """
    Plots convergence results. Plots the final train loss, final test loss, l2 error, l_infty error, against number of 
    collocations points, for each network used. 

    Parameters:
        df : dataframe
            dataframe generated by PINN_error_convergence
    """
    fig, ax = plt.subplots(2,2,constrained_layout=True)
    num_trainable_parameters_list = np.unique(df['num_trainable_params'].values)
    for ntp in num_trainable_parameters_list:
        df_restricted = df[df['num_trainable_params']==ntp]
        ax[0,0].loglog(df_restricted['num_colloc'], df_restricted['loss_train'], '*-', label = f"#trainable = {ntp}")        
        ax[0,1].loglog(df_restricted['num_colloc'], df_restricted['loss_test'], '*-', label = f"#trainable = {ntp}")        
        ax[1,0].loglog(df_restricted['num_colloc'], df_restricted['err_l2'], '*-', label = f"#trainable = {ntp}")        
        ax[1,1].loglog(df_restricted['num_colloc'], df_restricted['err_inf'], '*-', label = f"#trainable = {ntp}")        

    ax[0,0].legend(fontsize=6)
    ax[0,0].set_xlabel('Number collocation points')
    ax[0,1].set_xlabel('Number collocation points')
    ax[1,0].set_xlabel('Number collocation points')
    ax[1,1].set_xlabel('Number collocation points')
    ax[0,0].set_ylabel('Train loss')
    ax[0,1].set_ylabel('Test loss')
    ax[1,0].set_ylabel('$l_2$ error')
    ax[1,1].set_ylabel('$l_{\infty}$ error') 
    
    
    
def PINN_error_convergence(mms_problem,
                           num_colloc_array, 
                           num_layers_array,
                           neurons_per_layer_array,
                           num_epochs,
                           train_distribution,
                           use_best_test_loss,
                           learning_rate_decay,
                           output_file):
    """
    Using the PINN_solve function, perform an error convergence analysis varying the number of
    collocation points or the network architecture
    
    
    Parameters:
        mms_problem : string
           Should be "MMS1" or "MMS2". For MMS1, f(x) = -4*pi*pi*tf.math.sin(2*pi*x), g = 2*pi (solution is sinusoidal),
           for "MMS2" f(x) = (4*(x-0.5)**2 - 2)*tf.math.exp(-(x-0.5)**2) and g = -np.exp(-0.25) (solution is exponential)
        num_colloc_array : array
            array of integers, number of collocation points to be used
        num_layers_array : array
            array of integers, number of network layers points to be used
        neurons_per_layer_array : array
            array of integers, number of neurons per layer to be used
        num_epochs : int
            Number of epochs (iterations). Passed into PINN_Solve. 
        train_distribution : string
            How the collocation points will be distributed. Will be passed to dde.data.PDE(). Options
            include "uniform" or "pseudo" (randomly re-sampled each epoch). Passed into PINN_Solve. 
        use_best_test_loss : boolean
            Saves and restores the best performing weights, i.e., the weights for the iteration that provided 
            the lowest test loss. Passed into PINN_Solve. 
        output_file : string
            CSV file to be created containing all combinations of the results. All combinations of num_colloc, num_layers, 
            and num_neurons_per_layer will be run
    Returns:
        dataframe of results (also saved to output_file)
    """         
    
    
    # Helper function - computes the total number of trainable parameters in a network
    # given the number of layers and the number of neurons in each layer, 
    def get_num_trainable_params(num_layers, neurons_per_layer):
        return (num_layers+2)*neurons_per_layer + neurons_per_layer*neurons_per_layer*(num_layers-1) + 1 


    pi = tf.constant(math.pi)
    
    # Set up the problem to be solved
    if mms_problem == "MMS1":    
        bc = 2*pi
        def f(x):
            return - 4*pi*pi*tf.math.sin(2*pi*x)
        def exact_soln(x):
            return np.sin(2*np.pi*x)          
    elif mms_problem == "MMS2":
        bc = -np.exp(-0.25)
        def f(x):
            return (4*(x-0.5)**2 - 2)*tf.math.exp(-(x-0.5)**2)
        def bc_func(x):
            return 
        def exact_soln(x):
            return np.exp(-(x-0.5)**2) - np.exp(-0.25)   
    else:
        raise ValueError("mms_problem should be 'MMS1' or 'MMS2'")


    results = []

    # loop over all combinations of specificed inputs
    for nl, npl, nc in itertools.product(num_layers_array, neurons_per_layer_array, num_colloc_array):
        print("========================")
        print(f"nc={nc}, nl={nl}, npl={npl}")
        print("========================")

        N = 1001 # number of output points for the solve
        x, u, soln_info = PINN_solve(f, 
                                     bc,                
                                     num_output_points = N,
                                     num_colloc = nc,
                                     num_layers = nl,
                                     neurons_per_layer = npl,
                                     num_epochs = num_epochs,
                                     train_distribution=train_distribution,
                                     use_best_test_loss = use_best_test_loss,
                                     learning_rate_decay = learning_rate_decay)
        u_true = exact_soln(x)
        
        """
        from matplotlib import pyplot as plt
        fig, ax = plt.subplots()
        ax.plot(x,u,'r')
        ax.plot(x,u_true,'k')
        ax.set_title(f"NC = {nc}, NL = {nl}, NPL = {npl}")
        fig, ax = plt.subplots()
        ax.plot(soln_info['colloc_points'],soln_info['resid_at_colloc'],'k*')
        ax.plot(soln_info['x_dense'],soln_info['resid_at_x_dense'],'b')
        ax.set_title(f"NC = {nc}, NL = {nl}, NPL = {npl}")
        """

        err_l2  = np.linalg.norm(u-u_true)/np.sqrt(N)
        err_inf = np.max(np.abs(u-u_true))

        num_trainable_params = get_num_trainable_params(nl, npl)

        # final loss on training and test points (PDE component only)
        loss_train = soln_info['loss_train']
        loss_test = soln_info['loss_test']        
        
        results.append(
            {"num_colloc": nc,
             "num_layers": nl,
             "neurons_per_layer": npl,
             "num_trainable_params": num_trainable_params, 
             "err_l2": err_l2,
             "err_inf": err_inf,
             "loss_train": loss_train,
             "loss_test": loss_test})

        # save the current results rather than wait until the end, in case run is interrupted.
        df = pd.DataFrame(results)
        if output_file is not None:
            df.to_csv(output_file, index=False)    # save without the auto-generated index
        
    return df


